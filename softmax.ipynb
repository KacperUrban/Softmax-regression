{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c0505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76fd5a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62674a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: \n",
      "[[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]]\n",
      "Target: \n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = iris[\"data\"][:, (2,3)]\n",
    "y = iris[\"target\"]\n",
    "print(\"Data: \")\n",
    "print(X[:5, :])\n",
    "print(\"Target: \")\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4585e484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with bias: \n",
      "[[1.  1.4 0.2]\n",
      " [1.  1.4 0.2]\n",
      " [1.  1.3 0.2]\n",
      " [1.  1.5 0.2]\n",
      " [1.  1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "# Adding a bias equal to one\n",
    "X_with_bias = np.c_[np.ones([len(X), 1]), X]\n",
    "print(\"Data with bias: \")\n",
    "print(X_with_bias[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61908547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a germ of randomness \n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ddedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a validation, train and test set\n",
    "test_ratio = 0.2\n",
    "validation_ratio = 0.2\n",
    "total_size = len(X_with_bias)\n",
    "\n",
    "test_size = int(total_size * test_ratio)\n",
    "validation_size = int(total_size * validation_ratio)\n",
    "train_size = total_size - test_size - validation_size\n",
    "\n",
    "random_indexes = np.random.permutation(total_size)\n",
    "\n",
    "X_train = X_with_bias[random_indexes[:train_size]]\n",
    "y_train = y[random_indexes[:train_size]]\n",
    "X_validation = X_with_bias[random_indexes[train_size: -validation_size]]\n",
    "y_validation = y[random_indexes[train_size: -validation_size]]\n",
    "X_test = X_with_bias[random_indexes[-test_size:]]\n",
    "y_test = y[random_indexes[-test_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e039c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemenation of one hot encoding\n",
    "def to_one_hot(y):\n",
    "    number_of_classes = y.max() + 1\n",
    "    m = len(y)\n",
    "    Y_one_hot = np.zeros((m, number_of_classes))\n",
    "    Y_one_hot[np.arange(m), y] = 1\n",
    "    return Y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d0aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_one_hot = to_one_hot(y_train)\n",
    "Y_test_one_hot = to_one_hot(y_test)\n",
    "Y_validation_one_hot = to_one_hot(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2af241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax function\n",
    "def softmax(logits):\n",
    "    exps = np.exp(logits)\n",
    "    exp_sums = np.sum(exps, axis=1, keepdims=True)\n",
    "    return exps/exp_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e34bcfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input: 3\n",
      "Number of outputs: 3\n"
     ]
    }
   ],
   "source": [
    "# Define number of input and output\n",
    "n_inputs = X_train.shape[1]\n",
    "n_outputs = len(np.unique(y_train))\n",
    "print(\"Number of input:\", n_inputs)\n",
    "print(\"Number of outputs:\", n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "890c9b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.1558670968097458\n",
      "500 0.5037136804073767\n",
      "1000 0.37290732092550893\n",
      "1500 0.3181648078229816\n",
      "2000 0.2840738175795791\n",
      "2500 0.25966838973587675\n",
      "3000 0.24093253554723407\n",
      "3500 0.2259276257173829\n",
      "4000 0.21356013770955873\n",
      "4500 0.20314899741286405\n",
      "5000 0.19424017267038912\n"
     ]
    }
   ],
   "source": [
    "# Train a softmax model\n",
    "eta = 0.05\n",
    "n_iteration = 5001\n",
    "m = len(X_train)\n",
    "epsilon = 1e-7\n",
    "\n",
    "Theta = np.random.randn(n_inputs, n_outputs)\n",
    "\n",
    "for iteration in range(n_iteration):\n",
    "    logits = X_train.dot(Theta)\n",
    "    Y_proba = softmax(logits)\n",
    "    loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
    "    error = Y_proba - Y_train_one_hot\n",
    "    if iteration%500 == 0:\n",
    "        print(iteration, loss)\n",
    "    gradients = 1/m * X_train.T.dot(error)\n",
    "    Theta = Theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "029f75a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: \n",
      "[[ 5.60687481 -1.02439696 -7.40120651]\n",
      " [-1.2010688   0.87371521  0.43203466]\n",
      " [-2.07975966 -0.56278888  4.5593004 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model parameters: \")\n",
    "print(Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "179f4939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation of class membership: \n",
      "[[2.00871059e-01 7.09394171e-01 8.97347699e-02]\n",
      " [8.94217927e-06 5.28286645e-02 9.47162393e-01]\n",
      " [1.03040300e-03 6.06212094e-01 3.92757503e-01]\n",
      " [6.87136627e-04 8.42232117e-01 1.57080746e-01]\n",
      " [4.60611763e-06 6.24005163e-02 9.37594878e-01]]\n",
      "Selecting the class to which the example belongs: \n",
      "[1 2 1 1 2]\n",
      "Accuracy_score on validation set: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "logits = X_validation.dot(Theta)\n",
    "Y_proba = softmax(logits)\n",
    "print(\"Calculation of class membership: \")\n",
    "print(Y_proba[:5, :])\n",
    "y_predict = np.argmax(Y_proba, axis=1)\n",
    "print(\"Selecting the class to which the example belongs: \")\n",
    "print(y_predict[:5])\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_validation)\n",
    "print(\"Accuracy_score on validation set:\", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64516e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.3294787281046965\n",
      "500 0.545389888343696\n",
      "1000 0.5090543454418135\n",
      "1500 0.4961107501240011\n",
      "2000 0.48958713637665996\n",
      "2500 0.4858999583285211\n",
      "3000 0.4837012890713871\n",
      "3500 0.4823494945453566\n",
      "4000 0.48150164899360437\n",
      "4500 0.4809623748550879\n",
      "5000 0.4806158175804728\n"
     ]
    }
   ],
   "source": [
    "# Train a softmax model with regularization\n",
    "eta = 0.05\n",
    "n_iteration = 5001\n",
    "m = len(X_train)\n",
    "epsilon = 1e-7\n",
    "alpha = 0.1 # regularization parameter\n",
    "Theta = np.random.randn(n_inputs, n_outputs)\n",
    "\n",
    "for iteration in range(n_iteration):\n",
    "    logits = X_train.dot(Theta)\n",
    "    Y_proba = softmax(logits)\n",
    "    cross_entropy_loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
    "    l2_loss = 1/2*np.sum(np.square(Theta[1:]))\n",
    "    loss = cross_entropy_loss + l2_loss * alpha\n",
    "    error = Y_proba - Y_train_one_hot\n",
    "    if iteration%500 == 0:\n",
    "        print(iteration, loss)\n",
    "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
    "    Theta = Theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6ed0a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter: \n",
      "[[ 4.17368981  0.08964528 -4.45795554]\n",
      " [-1.08072598  0.19854501  0.88218098]\n",
      " [-0.42909805 -0.14691223  0.57601028]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model parameter: \")\n",
    "print(Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c856f32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation of class membership: \n",
      "[[0.44232519 0.47164103 0.08603378]\n",
      " [0.0056034  0.26512477 0.72927183]\n",
      " [0.02573494 0.46386078 0.51040428]\n",
      " [0.01305828 0.42172588 0.56521584]\n",
      " [0.00273738 0.21605628 0.78120634]]\n",
      "Selecting the class to which the example belongs: \n",
      "[1 2 2 2 2]\n",
      "Accuracy_score on validation set: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "logits = X_validation.dot(Theta)\n",
    "Y_proba = softmax(logits)\n",
    "print(\"Calculation of class membership: \")\n",
    "print(Y_proba[:5, :])\n",
    "y_predict = np.argmax(Y_proba, axis=1)\n",
    "print(\"Selecting the class to which the example belongs: \")\n",
    "print(y_predict[:5])\n",
    "\n",
    "accuracy_score = np.mean(y_predict == y_validation)\n",
    "print(\"Accuracy_score on validation set:\", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427e178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
